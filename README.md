# ğŸ“Š Lab 5 â€” Company Bankruptcy Prediction

This project implements an **end-to-end machine learning pipeline** for predicting company bankruptcy using the Taiwan Bankruptcy Dataset. It builds on **Lab 4 research decisions** and automates preprocessing, feature selection, model training, evaluation, and explainability.

## ğŸš€ Objectives
- Handle severe **class imbalance** (~3% bankrupt companies).
- Automate **data preprocessing** (imputation, outlier handling, correlation filter, scaling).
- Train & evaluate **three models**: Logistic Regression, Random Forest, and XGBoost.
- Compare performance using **ROC-AUC, PR-AUC, Brier Score, Accuracy**.
- Validate results with **calibration curves, SHAP explainability, and drift analysis**.
- Ensure **reproducibility** with fixed seeds and documented dependencies.

## âš™ï¸ Repository, Setup & Running

### Repository Structure
â”œâ”€â”€ artifacts/                # Generated outputs
â”‚   â”œâ”€â”€ curves/               # ROC, PR, Calibration plots
â”‚   â”œâ”€â”€ eda/                  # Class balance & correlation heatmap
â”‚   â”œâ”€â”€ drift/                # PSI drift checks
â”‚   â”œâ”€â”€ shap/                 # SHAP explainability plots
â”‚   â”œâ”€â”€ *.joblib              # Saved best models
â”‚   â”œâ”€â”€ selected_features.csv # Final feature set
â”‚   â””â”€â”€ model_comparison.csv  # Metrics summary
â”œâ”€â”€ REPORT.md                 # Lab 5 final report
â”œâ”€â”€ training_pipeline.py      # Main pipeline script
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore                # Ignore cache, venv, large files
text
### Setup & Installation
```bash
# Clone the repository
git clone <your-repo-url>
cd Lab5-Bankruptcy-Prediction

# Create virtual environment
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows

# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python training_pipeline.py --data_csv path/to/bankruptcy.csv --target "Bankrupt?" --out_dir artifacts
Dataset Overview

Rows Ã— Columns: 6819 Ã— 96
Target positive rate: 3.23%
Selected features: 63/95

Model Performance

ModelTest PR-AUCTest ROC-AUCAccuracyğŸŒ² RandomForest0.5560.9600.971âš¡ XGBoost0.5480.9580.969â• Logistic Reg0.4310.9480.863
ğŸ“ˆ Visual Results
ğŸ”¹ EDA

Class imbalance (rare bankruptcies):

<img src="artifacts/eda/class_balance.png" alt="Class Imbalance Plot">
Correlation heatmap (highly correlated features dropped):

<img src="artifacts/eda/correlation_heatmap.png" alt="Correlation Heatmap">

ğŸ”¹ Model Evaluation

ROC curves (how well models separate bankrupt vs safe companies):

<img src="artifacts/curves/roc_curves.png" alt="ROC Curves">
PR curves (focus on catching rare bankruptcies):

<img src="artifacts/curves/pr_curves.png" alt="PR Curves">
Calibration curves (how reliable probability predictions are):

<img src="artifacts/curves/calibration_curves.png" alt="Calibration Curves">

ğŸ”¹ Confusion Matrices (Test)

Logistic Regression
text[[1139, 181],
 [   6,  38]]

RandomForest
text[[1315,   5],
 [  34,  10]]

XGBoost
text[[1305,  15],
 [  27,  17]]


ğŸ”¹ Explainability & Stability

SHAP summary (key financial drivers of bankruptcy):

<img src="artifacts/shap/shap_summary.png" alt="SHAP Summary">
PSI Drift check (train vs test stability):

<img src="artifacts/drift/psi_drift.png" alt="PSI Drift">

ğŸ§© Challenges & Reflections

Severe class imbalance solved with class weighting (avoided SMOTE noise).
Random Forest & XGBoost achieved strong separation (high ROC-AUC).
Logistic Regression was better calibrated but weaker on recall.
Hyperparameter tuning balanced compute cost vs. performance (25 trials).
PSI checks confirmed stable train/test distributions â†’ confidence in deployment.
Lesson learned: Simple, interpretable methods with consistent preprocessing can still achieve strong, reproducible results.
